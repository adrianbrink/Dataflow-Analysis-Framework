
<!-- saved from url=(0061)http://pages.cs.wisc.edu/~horwitz/CS704-NOTES/2.DATAFLOW.html -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=windows-1252"><title>DATAFLOW ANALYSIS</title><style id="style-1-cropbar-clipper">/* Copyright 2014 Evernote Corporation. All rights reserved. */
.en-markup-crop-options {
    top: 18px !important;
    left: 50% !important;
    margin-left: -100px !important;
    width: 200px !important;
    border: 2px rgba(255,255,255,.38) solid !important;
    border-radius: 4px !important;
}

.en-markup-crop-options div div:first-of-type {
    margin-left: 0px !important;
}
</style></head>

<body><a name="top"><h1>Dataflow Analysis</h1></a>

<hr>
<h2>Contents</h2>
  <ul>
  <li> <a href="http://pages.cs.wisc.edu/~horwitz/CS704-NOTES/2.DATAFLOW.html#motivation">Motivation</a>
  </li><li> <a href="http://pages.cs.wisc.edu/~horwitz/CS704-NOTES/2.DATAFLOW.html#examples"> Examples of constant propagation and
       live-variable analysis</a>
       <ul>
       <li><a href="http://pages.cs.wisc.edu/~horwitz/CS704-NOTES/2.DATAFLOW.html#youtry1"> Test Yourself #1</a>
       </li></ul>
  </li><li> <a href="http://pages.cs.wisc.edu/~horwitz/CS704-NOTES/2.DATAFLOW.html#dataflow-problem"> Defining a dataflow problem</a>
       <ul>
       <li><a href="http://pages.cs.wisc.edu/~horwitz/CS704-NOTES/2.DATAFLOW.html#youtry2"> Test Yourself #2</a>
       </li></ul>
  </li><li> <a href="http://pages.cs.wisc.edu/~horwitz/CS704-NOTES/2.DATAFLOW.html#solutions"> Solving a dataflow problem</a>
       <ul>
       <li><a href="http://pages.cs.wisc.edu/~horwitz/CS704-NOTES/2.DATAFLOW.html#MOP">MOP Solution</a>
       </li><li><a href="http://pages.cs.wisc.edu/~horwitz/CS704-NOTES/2.DATAFLOW.html#equations">Solving a set of equations</a>
           <ul>
           <li><a href="http://pages.cs.wisc.edu/~horwitz/CS704-NOTES/2.DATAFLOW.html#youtry3"> Test Yourself #3</a>
           </li></ul>
       </li><li><a href="http://pages.cs.wisc.edu/~horwitz/CS704-NOTES/2.DATAFLOW.html#iterative"> Iterative algorithms</a>
           <ul>
           <li><a href="http://pages.cs.wisc.edu/~horwitz/CS704-NOTES/2.DATAFLOW.html#youtry4"> Test Yourself #4</a>
           </li></ul>
       </li><li> <a href="http://pages.cs.wisc.edu/~horwitz/CS704-NOTES/2.DATAFLOW.html#latticeModel"> The Lattice Model of DataflowAnalysis</a>
            <ul>
            <li><a href="http://pages.cs.wisc.edu/~horwitz/CS704-NOTES/2.DATAFLOW.html#latticeMotivation">Motivation</a>
            </li><li><a href="http://pages.cs.wisc.edu/~horwitz/CS704-NOTES/2.DATAFLOW.html#background">Background</a>
                <ul>
                <li><a href="http://pages.cs.wisc.edu/~horwitz/CS704-NOTES/2.DATAFLOW.html#poset">Partially ordered sets</a>
                </li><li><a href="http://pages.cs.wisc.edu/~horwitz/CS704-NOTES/2.DATAFLOW.html#finiteWidthLattice">Lattices</a>
                </li><li><a href="http://pages.cs.wisc.edu/~horwitz/CS704-NOTES/2.DATAFLOW.html#monotonic">Monotonic and distributive functions</a>
                </li><li><a href="http://pages.cs.wisc.edu/~horwitz/CS704-NOTES/2.DATAFLOW.html#fixedpoint">Fixed points</a>
                </li><li><a href="http://pages.cs.wisc.edu/~horwitz/CS704-NOTES/2.DATAFLOW.html#newlattices">Creating new lattices from old ones</a>
                </li><li><a href="http://pages.cs.wisc.edu/~horwitz/CS704-NOTES/2.DATAFLOW.html#latticeSummary">Summary of finiteWidthLattice theory</a>
                </li></ul>
            </li><li><a href="http://pages.cs.wisc.edu/~horwitz/CS704-NOTES/2.DATAFLOW.html#kildall">Kildall's Lattice Framework for Dataflow Analysis</a>
            </li></ul>
  </li><li> <a href="http://pages.cs.wisc.edu/~horwitz/CS704-NOTES/2.DATAFLOW.html#summary">Summary</a>
  </li></ul>
<hr>

<p>
<a name="motivation">
</a></p><h1><a name="motivation">Motivation for Dataflow Analysis</a></h1>
<p>
</p><p>
A compiler can perform some optimizations based only on local
information.  For example, consider the following code:
</p><pre>x = a + b;
x = 5 * 2;
</pre>
It is easy for an optimizer to recognize that:
<ul><li> The first assignment to x is a "useless" assignment, since
         the value computed for x is never used (and thus the first statement
         can be eliminated from the program).
    </li><li> The expression <em>5 * 2</em> can be computed at compile time,
         simplifying the second assignment statement to <em>x = 10;</em>
</li></ul>
<p>
Some optimizations, however, require more "global" information.
For example, consider the following code:
</p><pre>a = 1;
b = 2;
c = 3;
if (...) x = a + 5;
else x = b + 4;
c = x + 1;
</pre>
In this example, the initial assignment to c (at line 3) is useless,
and the expression <em>x + 1</em> can be simplified to 7, but it is
less obvious how a compiler can discover these facts since they cannot
be discovered by looking only at one or two consecutive statements.
A more <em>global</em> analysis is needed so that the compiler knows at each
point in the program:
<ul><li> which programParameters are guaranteed to have constant values, and
    </li><li> which programParameters will be used before being redefined.
</li></ul>
To discover these kinds of properties, we use <em>dataflow
analysis</em>.
Dataflow analysis is usually performed on the program's control-flow
graph (CFG);
the goal is to associate with each program component (each node of the
CFG) information that is guaranteed to hold at that point on all
executions.

<a name="examples">
<h1>Examples of constant propagation and live-variable
analysis</h1></a>

Below are examples illustrating two dataflow-analysis problems:
<em>constant propagation</em> and <em>live-variable analysis</em>.
Both examples use the following program:
<pre>1.   k = 2;
2.   if (...) {
3.     a = k + 2;
4.     x = 5;
5.   } else {
6.     a = k * 2;
7.     x = 8;
8.   }
9.   k = a;
10.  while (...) {
11.     b = 2;
12.     x = a + k;
13.     y = a * b;
14.     k++;
15.  }
16.  print(a+x);
</pre>

<p>
<em><u>Constant Propagation</u></em>
</p><p>
The goal of constant propagation is to determine where in the program
programParameters are guaranteed to have constant values.
More specifically, the information computed for each CFG node n is a
set of pairs, each of the form (variable, value).
If we have the pair (x, v) at node n, that means that
x is guaranteed to have value v whenever n is reached during
program execution.
</p><p>
Below is the CFG for the example program, annotated with
constant-propagation information.
</p><p>
<img src="./DATAFLOW ANALYSIS_files/CP.gif">
</p><p>
<em><u>Live-Variable Analysis</u></em>
</p><p>
The goal of live-variable analysis is to determine which programParameters are
"live" at each point in the program; a variable is live if its current
value might be used before being overwritten.  The information
computed for each CFG node is the set of programParameters that are live
immediately after that node.  Below is the CFG for the example
program, annotated with live variable information.
</p><p>
<img src="./DATAFLOW ANALYSIS_files/LV.gif">
</p><p>
</p><hr>
<a name="youtry1">
<p>
</p><center>
<u><b>TEST YOURSELF #1</b></u> </center></a>
<p>
Draw the CFG for the following program, and annotate it with
the constant-propagation and live-variable information that
holds before each node.
</p><pre>N = 10;
k = 1;
prod = 1;
MAX = 9999;
while (k &lt;= N) {
   read(num);
   if (MAX/num &lt; prod) { 
      print("cannot compute prod");
      break;
   }
   prod = prod * num;
   k++;
}
print(prod);
</pre>

<p><a href="http://pages.cs.wisc.edu/~horwitz/CS704-NOTES/DATAFLOW-AUX/DATAFLOW-ANSWERS.html#ans1">solution</a></p>
<hr>

<a name="dataflow-problem">
<h1>Defining a Dataflow Problem</h1></a>
<p>
Before thinking about how to define a dataflow problem, note that
there are <em>two</em> kinds of problems:
</p><ul>
  <li> Forward problems (like constant propagation) where the
       information at a node n summarizes what can happen on paths from
       "enter" to n.
  </li><li> Backward problems (like live-variable analysis), where the
       information at a node n summarizes what can happen on paths from n
       to "exit".
</li></ul>

In what follows, we will assume that we're thinking about a forward
problem unless otherwise specified.
<p>
Another way that many common dataflow problems can be categorized is
as <em>may</em> problems or <em>must</em> problems.  The solution to a
"may" problem provides information about what <em>may</em> be true at
each program point (e.g., for live-programParameters analysis, a variable is
considered live after node n if its value <em>may</em> be used before
being overwritten, while for constant propagation, the pair (x, v)
holds before node n if x <em>must</em> have the value v at
that point).
</p><p>
Now let's think about how to define a dataflow problem so that it's
clear what the (best) solution should be.  When we do dataflow
analysis "by hand", we look at the CFG and think about:
</p><ul>
  <li> What information holds at the start of the program.
  </li><li> When a node n has more than one incoming edge in the CFG,
       how to combine the incoming information (i.e., given the
       information that holds after each predecessor of n, how to
       combine that information to determine what holds before n).
  </li><li> How the execution of each node changes the information.
</li></ul>
<p>
This intuition leads to the following definition.  An <em>instance of
a dataflow problem</em> includes:
</p><ul>
  <li> a CFG,
  </li><li> a domain D of "dataflow facts",
  </li><li> a dataflow fact "init" (the information true at the start of
       the program for forward problems, or at the end of the program
       for backward problems),
  </li><li> an operator &#8968;&#8969; (used to combine incoming information
       from multiple predecessors), </li><li> for each CFG node n, a dataflow
       function <em>f<sub>n</sub> : D &#8594; D</em> (that defines the
       effect of executing n).
</li></ul>
<p>
For constant propagation, an individual dataflow fact is a set of
pairs of the form (var, val), so the domain of dataflow facts is the set of
all such sets of pairs (the power set).
For live-variable analysis, it is the power set of the set of
programParameters in the program.
</p><p>
For both constant propagation and live-variable analysis,
the "init" fact is the empty set
(no variable starts with a constant value, and no
programParameters are live at the end of the program).
</p><p>
For constant propagation, the combining operation &#8968;&#8969; is
set intersection.
This is because if a node n has two predecessors, p1 and p2,
then variable x has value v before node n iff it has value v after
both p1 and p2.
For live-variable analysis, &#8968;&#8969; is set
union: if a node n has two successors, s1 and s2, then the value of x
after n may be used before being overwritten iff that holds either
before s1 or before s2.  In general, for "may" dataflow problems,
&#8968;&#8969; will be some union-like operator, while it will be an
intersection-like operator for "must" problems.
</p><p>
For constant propagation, the dataflow function associated with a CFG
node that does not assign to any variable (e.g., a predicate) is the
identity function.
For a node n that assigns to a variable x, there are two possibilities:
</p><ol>
  <li> The right-hand side has a variable that is not constant.
       In this case, the function result is the same as its input
       except that if variable x was constant the before n,
       it is not constant after n.
  </li><li> All right-hand-side programParameters have constant values.
       In this case, the right-hand side of the assignment is evaluated
       producing consant-value c, and the dataflow-function result is
       the same as its input except that it includes the pair (x, c) for
       variable x (and excludes the pair for x, if any, that was in
       the input).
</li></ol>
<p>
For live-variable analysis, the dataflow function for each node n
has the form:
<em>f<sub>n</sub>(S) = (S - KILL<sub>n</sub>) union GEN<sub>n</sub></em>,
where <em>KILL<sub>n</sub></em> is the set of programParameters defined at node n, and
<em>GEN<sub>n</sub></em> is the set of programParameters used at node n.  In other
words, for a node that does not assign to any variable, the programParameters
that are live before n are those that are live after n plus those that
are used at n; for a node that assigns to variable x, the programParameters
that are live before n are those that are live after n <em>except</em>
x, plus those that are used at n (including x if it is used at n as
well as being defined there).
</p><p>
An equivalent way of formulating the dataflow functions for
live-variable analysis is: <em>f<sub>n</sub>(S) = (S intersect
NOT-KILL<sub>n</sub>) union GEN<sub>n</sub></em>, where
<em>NOT-KILL<sub>n</sub></em> is the set
of programParameters <em>not</em> defined at node n.  The advantage of this
formulation is that it permits the dataflow facts to be represented
using bit vectors, and the dataflow functions to be implemented using
simple bit-vector operations (<b>and</b>
<b>or</b>).
</p><p>
It turns out that a number of interesting dataflow problems have
dataflow functions of this same form, where GEN<sub>n</sub> and
KILL<sub>n</sub> are sets whose definition depends only on n, and
the combining operator &#8968;&#8969; is either union or intersection.
These problems are called <em>GEN/KILL</em> problems, or
<em>bit-vector</em> problems.
</p><p>
</p><hr>
<a name="youtry2">
<p>
</p><center>
<u><b>TEST YOURSELF #2</b></u> </center></a>
<p>
Consider using dataflow analysis to determine which programParameters might be
used before being initialized; i.e., to determine, for each point in
the program, for which programParameters there is a path to that point on which
the variable was never defined.
Define the "may-be-uninitialized" dataflow problem by specifying:
</p><ul> <li> the domain D of "dataflow facts",
     </li><li> the operator &#8968;&#8969;,
     </li><li> the "init" dataflow fact,
     </li><li> a dataflow function for each CFG node n.
</li></ul>
Annotate the CFG for the example program from TEST YOURSELF #1 with
the solution to the problem (the information that holds before each
node).
<p>
If you did not define the may-be-uninitialized problem as a GEN/KILL
problem, go back and do that now (i.e., say what the GEN and KILL sets
should be for each kind of CFG node, and whether &#8968;&#8969; should
be union or intersection).

</p><p><a href="http://pages.cs.wisc.edu/~horwitz/CS704-NOTES/DATAFLOW-AUX/DATAFLOW-ANSWERS.html#ans2">solution</a></p>
<hr>

<a name="solutions">
<h1>Solving a Dataflow Problem</h1></a>
<p>
A solution to an instance of a dataflow problem is a dataflow fact for
each node of the given CFG.  But what does it mean for a solution to
be correct, and if there is more than one correct solution, how can we
judge whether one is better than another?
</p><p>
Ideally, we would like the information at a node to reflect what might
happen on all possible paths to that node.  This ideal solution is
called the <em>meet over all paths (MOP)</em> solution, and is
discussed below.  Unfortunately, it is not always possible to compute
the MOP solution; we must sometimes settle for a solution that
provides less precise information.

<a name="MOP">
</a></p><h2><a name="MOP">The "Meet Over All Paths" Solution</a></h2><a name="MOP">
<p>
The MOP solution (for a forward problem) for each CFG node n is
defined as follows: </p><ul> <li> For every path "enter &#8594; ... &#8594;
n", compute the dataflow fact induced by that path (by applying the
dataflow functions associated with the nodes on the path to the
initial dataflow fact).  </li><li> Combine the computed facts (using the
combining operator, &#8968;&#8969; ).  </li><li> The result is the MOP
solution for node n.  </li></ul>
<p>
For instance, in our running example program there are two paths from
the start of the program to line 9 (the assignment <em>k = a</em>):

<br>&nbsp; </p><center><table border="1" width="50%"> <tbody><tr>
<th><center><em>Path</em></center></th> <th><center><em>Constants
associated w/ that path</em></center></th> </tr>

<tr>
<th><center>1 &#8594; 2 &#8594; 3 &#8594; 4 &#8594; 9</center></th>
<th><center>k=2, a=4, x=5</center></th> </tr>

<tr>
<th><center>1 &#8594; 2 &#8594; 6 &#8594; 7 &#8594; 9</center></th>
<th><center>k=2, a=4, x=8</center></th> </tr> </tbody></table></center>
<p>
Combining the information from both paths, we see that the MOP
solution for node 9 is: k=2 and a=4.

</p><p>
It is worth noting that even the MOP solution can be overly
conservative (i.e., may include too much information for a "may"
problem, and too little information for a "must" problem), because not
all paths in the CFG are executable.  For example, a program may
include a predicate that always evaluates to <em>false</em> (e.g., a
programmer may include a test as a debugging device -- if the program
is correct, then the test will always fail, but if the program
contains an error then the test might succeed, reporting that error).
Another way that non-executable paths can arise is when two predicates
on the path are not independent (e.g., whenever the first evaluates to
<em>true</em> then so does the second).  These situations are
illustrated below.
</p><ul>
  <br><img src="./DATAFLOW ANALYSIS_files/UnexecutablePath.gif">
</ul>
</a><p><a name="MOP">
Unfortunately, since most programs include loops, they also have
infinitely many paths, and thus it is not possible to compute the MOP
solution to a dataflow problem by computing information for every path
and combining that information.  Fortunately, there are other ways to
solve dataflow problems (given certain reasonable assumptions about
the dataflow functions associated with the CFG nodes).  As we shall
see, if those functions are <em>distributive</em>, then the solution
that we compute is identical to the MOP solution.  If the functions
are <em>monotonic</em>, then the solution may not be identical to the
MOP solution, but is a conservative approximation.

</a><a name="equations">
</a></p><h2><a name="equations">Solving a Dataflow Problem by Solving a Set of Equations</a></h2><a name="equations">
<p>
The alternative to computing the MOP solution directly, is to solve a
system of equations that essentially specify that local information
must be consistent with the dataflow functions.  In particular, we
associate two dataflow facts with each node n:
</p><ol>
  <li> <em>n.before</em>: the information that holds before n executes, and
  </li><li> <em>n.after</em>: the information that holds after n executes.
</li></ol>
These n.befores and n.afters are the programParameters of our equations,
which are defined as follows (two equations for each node n):
<ol>
  <li> n.before = &#8968;&#8969;(p1.after, p2.after, ...)<br> where p1,
       p2, etc are n's predecessors in the CFG (and &#8968;&#8969; is the
       combining operator for this dataflow problem).
  </li><li> n.after = <em>f<sub>n</sub></em> ( n.before )
</li></ol>
In addition, we have one equation for the enter node:
<ul>
  <li> enter.after = init (recall that "init" is part of the specification
       of a dataflow problem)
</li></ul> These equations make intuitive sense: the dataflow
information that holds before node n executes is the combination of
the information that holds after each of n's predecessors executes,
and the information that holds after n executes is the result of
applying n's dataflow function to the information that holds before n
executes.
<p>
One question is whether, in general, our system of equations will have
a unique solution.  The answer is that, in the presence of loops,
there may be multiple solutions.  For example, consider the simple
program whose CFG is given below:
</p><p>
</p><center>
<br><img src="./DATAFLOW ANALYSIS_files/mult-solution.gif"> </center>
<p>
The equations for constant propagation are as follows (where
&#8968;&#8969; is the intersection combining operator):
</p><ul>
  enter.after = empty set <br>
  1.before = enter.after <br>
  1.after = 1.before - (x, *) union (x, 2) <br>
  2.before = 1.after <br>
  2.after = if (x, c) is in 2.before then 2.before - (y, *) union (y, c), else 2.before - (y, *)<br>
  3.before = &#8968;&#8969;(2.after, 4.after ) <br>
  3.after = 3.before <br>
  4.before = 3.after <br>
  4.after = 4.before
</ul>
Because of the cycle in the example CFG, the equations for
<em>3.before</em>, <em>3.after</em>, <em>4.before</em>, and
<em>4.after</em> are mutually recursive, which leads to the
four solutions shown below (differing on those four values).
<p>
</p><center><table border="" width="50%">
<tbody><tr>
 <td><center><em>Variable</em></center></td>
 <td><center><em>Solution 1</em></center></td>
 <td><center><em>Solution 2</em></center></td>
 <td><center><em>Solution 3</em></center></td>
 <td><center><em>Solution 4</em></center></td>
</tr>

<tr>
 <td><center>1.before</center></td>
 <td><center>{ }</center></td>
 <td><center>{ }</center></td>
 <td><center>{ }</center></td>
 <td><center>{ }</center></td>
</tr>

<tr>
 <td><center>1.after</center></td>
 <td><center>{(x, 2)}</center></td>
 <td><center>{(x, 2)}</center></td>
 <td><center>{(x, 2)}</center></td>
 <td><center>{(x, 2)}</center></td>
</tr>

<tr>
 <td><center>2.before</center></td>
 <td><center>{(x, 2)}</center></td>
 <td><center>{(x, 2)}</center></td>
 <td><center>{(x, 2)}</center></td>
 <td><center>{(x, 2)}</center></td>
</tr>

<tr>
 <td><center>2.after</center></td>
 <td><center>{(x, 2) (y, 2)}</center></td>
 <td><center>{(x, 2) (y, 2)}</center></td>
 <td><center>{(x, 2) (y, 2)}</center></td>
 <td><center>{(x, 2) (y, 2)}</center></td>
</tr>

<tr>
 <td><center>3.before</center></td>
 <td><center>{ }</center></td>
 <td><center>{(x, 2)}</center></td>
 <td><center>{(y, 2)}</center></td>
 <td><center>{(x, 2) (y, 2)}</center></td>
</tr>

<tr>
 <td><center>3.after</center></td>
 <td><center>{ }</center></td>
 <td><center>{(x, 2)}</center></td>
 <td><center>{(y, 2)}</center></td>
 <td><center>{(x, 2) (y, 2)}</center></td>
</tr>

<tr>
 <td><center>4.before</center></td>
 <td><center>{ }</center></td>
 <td><center>{(x, 2)}</center></td>
 <td><center>{(y, 2)}</center></td>
 <td><center>{(x, 2) (y, 2)}</center></td>
</tr>

<tr>
 <td><center>4.after</center></td>
 <td><center>{ }</center></td>
 <td><center>{(x, 2)}</center></td>
 <td><center>{(y, 2)}</center></td>
 <td><center>{(x, 2) (y, 2)}</center></td>
</tr>
</tbody></table></center>
<p>
The solution we want is solution 4, which includes the most constant
information.  In general, for a "must" problem the desired solution
will be the largest one, while for a "may" problem the desired
solution will be the smallest one.
</p><p>
</p><hr>
</a><a name="youtry3">
<p>
</p><center>
<u><b>TEST YOURSELF #3</b></u> </center></a>
<p>
Using the simple CFG given above, write the equations for
live-variable analysis, as well as the greatest and least solutions.
Which is the desired solution, and why?

</p><p><a href="http://pages.cs.wisc.edu/~horwitz/CS704-NOTES/DATAFLOW-AUX/DATAFLOW-ANSWERS.html#ans3">solution</a></p>

<hr>
<p>
Many different algorithms have been designed for solving a dataflow
problem's system of equations.  Most can be classified as either
<em>iterative algorithms</em> or <em>elimination</em> algorithms.
These two classes of algorithms are discussed in the next two
sections.

<a name="iterative">
</a></p><h2><a name="iterative">Iterative Algorithms</a></h2><a name="iterative">
<p>
Most of the iterative algorithms are variations on the following
algorithm (this version is for forward problems).
It uses a new value T (called "top").  T has the property
that, for all dataflow facts d, T &#8968;&#8969; d = d.
Also, for all dataflow functions, <em>f</em><sub>n</sub>(T) = T.
(When we consider the finiteWidthLattice model for dataflow analysis we will see
that this initial value is the top element of the finiteWidthLattice.)

</p><ul>
  <li> <em>Step 1 (initialize n.afters)</em>: <br>
       Set enter.after = init.  Set all other n.after to T.
  </li><li> <em>Step 2 (initialize worklist)</em>: <br>
       Initialize a worklist to contain all CFG nodes except enter
       and exit.
  </li><li> <em>Step 3 (iterate)</em>: <br>
       While the worklist is not empty:
       <ul> Remove a node n from the worklist.  <br>
            Compute n.before by combining all p.after such that p
	    is a predecessor of n in the CFG.  <br> Compute
	    tmp = <em>f<sub>n</sub></em> ( n.before ) <br>
	    If (tmp != n.after) then
	    <ul> Set n.after = tmp <br>
	         Put all of n's successors on the worklist
	    </ul>
       </ul>
</li></ul>
<p>
</p><hr>
</a><a name="youtry4">
<p>
</p><center>
<u><b>TEST YOURSELF #4</b></u> </center></a>
<p>
Run this iterative algorithm on the simple CFG given above (the one with
a loop) to solve the constant propagation problem.
Run the algorithm again on the example CFG from the
<a href="http://pages.cs.wisc.edu/~horwitz/CS704-NOTES/2.DATAFLOW.html#examples">examples</a> section of the notes.
</p><hr>
<p>
This algorithm works regardless of the order in which nodes are
removed from the worklist.  However, that order can affect the
efficiency of the algorithm.  A number of variations have been
developed that involve different ways of choosing that order.
When we consider the finiteWidthLattice model, we will revisit the question of
complexity.

<a name="latticeModel">
</a></p><h2><a name="latticeModel">The Lattice Model of Dataflow Analysis</a></h2>

<a name="latticeMotivation">
<h3>Motivation</h3></a>
Recall that while we would like to compute the meet-over-all-paths (MOP)
solution to a dataflow problem, direct computation of that solution
(by computing and combining solution for every path) is usually not
possible.
Therefore, dataflow problems are usually solved by finding a solution
to a set of equations that define two dataflow facts (n.before and n.after)
for each CFG node n.
<p>
Three important questions are:
</p><ol>
  <li> How do we know that a solution to the equations exists?
  </li><li> If there is more than one solution, which one do we want?
  </li><li> How does the equation solution relate to MOP solution?
</li></ol>
<p>
The answers are provided by the framework first defined by Kildall.
The next section provides background on lattices;
the section after that presents Kildall's framework.

<a name="background">
</a></p><h3><a name="background">Background</a></h3>

<a name="poset">
<h4><u>Partially ordered sets</u></h4></a>
<p>
<b>Definition:</b>
</p><ul>
  A <b>partially ordered set </b> (poset) is a set S that has a
  partial ordering &#8838; , such that the ordering is:
    <ol>
  	<li> <u>Reflexive:</u> for all x in S, x &#8838; x
  	</li><li> <u>Anti-Symmetric:</u> for all x,y in S, x &#8838; y and 
  	     y &#8838; x implies x = y
  	</li><li> <u>Transitive:</u> for all x,y,z in S, x &#8838; y and y &#8838; z
  	     implies x &#8838; z
    </li></ol>
  <p>
  Note: "partial" means it is <em>not</em> necessary that for all x,y in S,
  either x &#8838; y or y &#8838; x.
  It is OK for a pair of set elements to be incomparable.
</p></ul>

Below are some examples of sets with orderings;
some are partially ordered sets and some are not.
<p>
<b>Example 1:</b>
The set S is the set of English words, and the ordering &#8838; is
substring (i.e., w1 &#8838; w2 iff w1 is a substring of w2).
Here is a picture of some words and their ordering (having an
edge w1 &#8594; w2 means w1 &gt; w2).

</p><pre>                         candy                  then
                         /    \                /    \
                         v     v              v      v
                annual  and   can            the   hen
                     \   |    /                \   /
                      \  |   /                  v v
                       v v  v                    he
                         an
                         |
                         v
                         a

</pre>
Note that the "substring" ordering does have the three properties
required of a partial order:
<ol>
  <li> It is reflexive (since every word is a substring of itself).
  </li><li> It is anti-symmetric (since if two words are substrings
       of each other, then they must be the same).
  </li><li> It is transitive (since a substring of a substring of a word
       is also a substring of the word).
</li></ol>
<p>
<b>Example 2</b>:
S is the set of English words, and the ordering &#8838; is
"is shorter than or equal to in length".
</p><pre>                candy
                  |
                  v
           ____ then
          /    /  |  \
          v   v   v   v
         can and the hen
           \  \   /   /
            \  \ /   /
             v v v   v
               an
                |
                v
                a
</pre>
Does this ordering have the three properties?
<ol>
  <li> Reflexive: yes.
  </li><li> Anti-Symmetric: NO
       (Counter-example: "and" and "the" have the same length, but
       are <em>not</em> the same word.)
  </li><li> Transitive: yes.
</li></ol>
Two out of three isn't good enough -- this is <b>not</b> a poset.
<p>

<b>Example 3</b>:
S is the set of integers, and the ordering &#8838; is "less than or equal to".
This <b>is</b> a poset (try verifying each of the three properties).
</p><p>

<b>Example 4</b>:
S is the set of integers and the ordering &#8838; is "strictly less than".
This is <b>not</b> a poset, because the ordering is not reflexive.
</p><p>

<b>Example 5</b>:
S is the set of all sets of letters and the ordering is subset.
This <b>is</b> a poset.
</p><p>

<a name="finiteWidthLattice">
</a></p><h4><a name="finiteWidthLattice"><u>Lattices</u></a></h4>
<p>
<b>Definition:</b>
</p><ul>
  A <b>finiteWidthLattice </b> is a poset in which every pair of elements has:
  <ol>
    <li> a <u>Least Upper Bound</u> (the <em>join</em> of the
         two elements), and
    </li><li> a <u>Greatest Lower Bound </u> (the <em>meet</em> of the two
         elements).
  </li></ol>
</ul>

The join of two elements x and y is defined to be the element z such that:
<ol>
  <li> x &#8838; z, and
  </li><li> y &#8838; z, and
  </li><li> for all w such that x &#8838; w and y &#8838; w, w &#8839; z.
</li></ol>
The first two rules say that z actually is an upper bound for
x and y, while the third rule says that z is the <em>least</em>
upper bound.
Pictorially:
<pre>        z
       / \              z is the least upper bound of x and y
      v   v
      y   x 

       z  w
       |\/|
       |/\|             z is NOT the least upper bound of x and y
       vv vv            (they have NO least upper bound)
       y  z     
</pre>

The idea for the meet operation is similar, with the reverse orderings.

<h5>Examples:</h5>
<ul>
  <li> Example 1 above (English words, ordered by "substring")
       is <b>not</b> a finiteWidthLattice.
       (For instance, "a" and "he" have no meet.)
  </li><li> Example 3 above (integers, ordered by "less than or equal to")
       <b>is</b> a finiteWidthLattice.  The meet operator is  "min"
       and the join operator is "max".
  </li><li> Example 5 above (sets of letters, ordered by subset)
       <b>is</b> a finiteWidthLattice.  The meet operator is intersection
       and the join operator is union.
</li></ul>

<a name="complete finiteWidthLattice">
<h4><u>Complete lattices</u></h4></a>
<b>Definition: </b>
<ul>
  A <b>complete finiteWidthLattice </b> is a finiteWidthLattice in which all <em>subsets</em> have
  a greatest lower bound and a least upper bound (the bounds must be in
  the finiteWidthLattice, but not necessarily in the subsets themselves).
</ul>
<p>
Note: Every finite finiteWidthLattice (i.e., S is finite) is complete.
</p><p>
</p><h4> Examples:</h4>
<ul>
  <li> Example 3 above (integers, ordered by "less than or equal to")
       is <b>not</b> a complete finiteWidthLattice.
       The set of all positive numbers is a subset of S;
       it has a lower bound but no upper bound.
       <br>
       The set of all even numbers is a subset of S;
       it has neither an upper nor a lower bound.
  </li><li> The set: {1, 1/2, 1/4, 1/8, ... 0} with the usual numeric ordering
       is an example of an <em>infinite</em> complete finiteWidthLattice.
</li></ul>
<p>
Note: Every complete finiteWidthLattice has a greatest element, "Top" (written
as a capital T) and a least
element "Bottom" (written as an upside-down capital T).
They are the least-upper and the
greatest-lower bounds of the entire underlying set S.

<a name="monotonic">
</a></p><h4><a name="monotonic"><u>Monotonic and distributive functions</u></a></h4>
<b>Definition:</b>
<ul> 
  A function f: L &#8594; L (where L is a finiteWidthLattice)
  is <b>monotonic</b> iff for all x,y in L:
  x &#8838; y implies f(x) &#8838; f(y).
</ul>

<b>Definition:</b>
<ul> 
  A function f: L &#8594; L (where L is a finiteWidthLattice)
  is <b>distributive</b> iff for all x,y in L:
  f(x meet y) = f(x) meet f(y).
</ul>

<p>
Every distributive function is also monotonic (proving that could
be good practice!) but not vice versa.
For the GEN/KILL dataflow problems, all dataflow functions are
distributive.
For constant propagation, all functions are monotonic, but not
all functions are distributive.
For example, the dataflow function f associated with this assignment
</p><ul>
x = a + b
</ul>
is not distributive.
To see this, first recall that function f is defined as follows:
<ul>
<table>
<tbody><tr><td>f(S) = </td><td>if S == T then T
</td></tr><tr><td>       </td><td>else if (a, v1) in S and (b, v2) in S then S - (x,*) + (x, v1+v2)
</td></tr><tr><td>       </td><td>else S - (x,*)
</td></tr></tbody></table>   
</ul>
i.e., if f is applied to the special "top" value, then the result is T;
otherwise, if both a and b are constant, then x is set to have the
value of a+b (and its old value, if any, is removed from the
set of pairs);
otherwise, x's old value, if any, is removed from the
set of pairs.
</li></ul>
Now consider the following two sets:
<ul>
S1 = { (a,1) (b,2) }
S2 = { (a,2) (b,1) }
</ul>
The meet of S1 and S2 is { }
So f(S1 meet S1) is { }.
However, if we apply f to S1 and S2 and <emph>then</emph> take the meet
we get this:
<ul>
f(S1) = {(a,1)(b,2)(x,3)} <br>
f(S1) = {(a,2)(b,1)(x,3)} <br>
f(S1) meet f(S2) = {(x,3)}
</ul>
<a name="fixedpoint">
<h4><u>Fixed points</u></h4>
<b>Definition:</b>
<ul> 
  x is a <b>fixed point </b> of function f iff f(x) = x.
</ul>
<p>

</p><h4>Examples:</h4>
Let L be the finiteWidthLattice whose elements are sets of letters (as above).
Here are the fixed points for the functions we considered above:
<ol>
  <li> f(S) = S union {a}
       <br>
       This function has many fixed points: all sets that contain 'a'.
  </li><li> f(S) = if sizeof(S) &#8804; 3 then S else empty-set
       <br>
       The fixed points for this function are all
       sets of size less than or equal to 3
  </li><li> f(S) = S - {a}
       <br>
       The fixed points for this function are all
       sets that do <em>not</em> contain 'a'.
</li></ol>
As an example of a function that has no fixed point, consider
the finiteWidthLattice of integers with the usual "less than or equal to"
ordering.
The function: f(x) = x+1 has no fixed point.

<p>
Here is an important theorem about lattices and monotonic functions:
</p><p>
<b>Theorem:</b>
</p><ul> 
  If L is a complete finiteWidthLattice and f: L &#8594; L is monotonic, then:
  <ul>
    <li> f has at least one fixed point.
    </li><li> f's fixed points themselves form a (complete) finiteWidthLattice. (i.e.
         there exist greatest and least fixed points).
    </li><li> If L has no infinite descending chains, then the greatest
         fixed point of f can be found by iterating:
         <ul>
            f(T), f(f(T)), f(f(f(T))), ... 
         </ul>
         until a fixed point is found (i.e., two successive values are
         the same).  (Note that "T" means L's top element.)
    </li><li> Similarly, if L has no infinite ascending chains, then the least
         fixed point of f can be found by iterating
	 <ul>
	   f(bottom), f(f(bottom)) ...
	 </ul>
	 until a fixed point is found.
  </li></ul>
</ul>

<h4>Examples</h4>
L is our usual finiteWidthLattice of sets of letters, with set union for the join.
<ol>
  <li> f(S) = S U {a}
       <br>
       Recall that f <em>is</em> monotonic.
       The greatest fixed point of f is the set of all letters: {a, b, ..., z}.
       That is also the top element of the finiteWidthLattice, so we find the
       greatest fixed point in just one iteration:
       <ul>
         f(T) = T
       </ul>
       The bottom element is the empty set.
       If we apply f to that we get the set {a}.
       f({a}) = {a}, and we've found the least fixed point.
       Other fixed points are any set of letters that contains a.
  <p>
  </p></li><li> f(S) = if size(S) &#8804; 3 then S else {}
       <br>
        Recall that this function f is <em>not</em> monotonic.
        It has no greatest fixed point.
        It does have a least fixed point (the empty set).
        Other fixed points are sets of letters with size &#8804; 3.
</li></ol>

</a><a name="newlattices">
<h4><u>Creating new lattices from old ones</u></h4></a>
<p>
We can create new lattices from old ones using <em>cross-product</em>:
if L1, L2, ..., Ln are lattices, then so is the cross-product
of L1, L2, ..., Ln (which we can write as: L1 x L2 x ... x Ln).
The elements of the cross-product are tuples of the form:
   </p><ul>
       &lt;e<sub>1</sub>, e<sub>2</sub>, ... , e<sub>n</sub>&gt;
   </ul>
   such that value e<sub>k</sub> belongs to finiteWidthLattice Lk
   <p>
   The ordering is element-wise:
     &lt;e<sub>1</sub>, e<sub>2</sub>, ..., e<sub>n</sub>&gt; &#8838;
     &lt;e<sub>1</sub>', e<sub>2</sub>', ..., e<sub>n</sub>'&gt; iff:
     </p><ul>
            e<sub>1</sub> &#8838; e<sub>1</sub>' and
       <br> e<sub>2</sub> &#8838; e<sub>2</sub>', and
       <br> ..., and
       <br> e<sub>n</sub> &#8838; e<sub>n</sub>'
     </ul>
<p>
If L1, L2, ..., Ln are <em>complete</em> lattices, then so is their
cross-product.
The top element is the tuple that contains the top elements
of the individual lattices:
&lt;top of L1, top of L2, ... , top of Ln&gt;, and the
bottom element is the tuple that contains the bottom elements of
the individual lattices:
&lt;bottom of L1, bottom of L2, ... , bottom of Ln&gt;.

<a name="latticeSummary">
</a></p><h4><a name="latticeSummary"><u>Summary of finiteWidthLattice theory</u></a></h4><a name="latticeSummary">
<ul>
<li><b>poset</b>: a partially ordered set, includes a set of elements S and a
	   partial ordering &#8838;
</li><li><b>finiteWidthLattice</b>: a poset with meet and join for every pair of elements
</li><li><b>complete finiteWidthLattice</b>:
	a finiteWidthLattice with meet and join for all subsets of S
</li><li><b>monotonic functions</b>: x &#8838; y implies f(x) &#8838; f(y)
</li><li><b>fixed points</b>:
        x is a fixed point of function f (of type L&#8594;L) iff x = f(x). <br>
	If L is a complete finiteWidthLattice and f is monotonic,
	then f has a greatest and a least fixed point. <br>
	If L has no infinite descending chains then we can compute the
	greatest fixed point of f via iteration ( f(T), f(f(T)) etc.)
</li></ul>

</a><a name="kildall">
<h3>Kildall's Lattice Framework for Dataflow Analysis</h3>
<p>
Recall that our informal definition of a dataflow problem included:
</p><ul>
  <li> a domain D of "dataflow facts",
  </li><li> a dataflow fact "init" (the information true at the
       start of the program),
  </li><li> an operator &#8968;&#8969;  (used to combine incoming information from
       multiple predecessors),
  </li><li> for each CFG node n, a dataflow function
       <em>f<sub>n</sub> : D &#8594; D</em>
       (that defines the effect of executing n)
</li></ul>
and that our goal is to solve a given instance of the problem
by computing "before" and "after" sets for each node of the control-flow
graph.
A problem is that, with no additional information about the domain D, the
operator &#8968;&#8969; , and the dataflow functions f<sub>n</sub>, we can't say, in
general, whether a particular algorithm for computing the before and
after sets works correctly (e.g., does the algorithm always halt?
does it compute the MOP solution?  if not, how does the computed solution
relate to the MOP solution?).
<p>
Kildall addressed this issue by putting some additional requirements
on D, &#8968;&#8969; , and f<sub>n</sub>.
In particular he required that:
</p><ol>
  <li> D be a <em>complete finiteWidthLattice</em> L such that for any
       <em>instance</em> of the dataflow problem, L has no
       infinite descending chains.
  </li><li> &#8968;&#8969;  be the finiteWidthLattice's meet operator.
  </li><li> All f<sub>n</sub> be <em>distributive</em>.
</li></ol>
He also required (essentially) that the iterative algorithm initialize
n.after (for all nodes n other than the enter node) to the finiteWidthLattice's
"top" value.
(Kildall's algorithm is slightly different from the iterative algorithm
presented here, but computes the same result.)
<p>
Given these properties, Kildall showed that:
</p><ul>
  <li> The iterative algorithm always terminates.
  </li><li> The computed solution is the MOP solution.
</li></ul>
It is interesting to note that, while his theorems are correct,
the example dataflow problem that he uses (constant propagation)
does <em>not</em> satisfy his requirements;
in particular, the dataflow functions for constant propagation
are not distributive (though they are monotonic).
This means that the solution computed by the iterative algorithm
for constant propagation will not, in general be the MOP solution.
Below is an example to illustrate this:
<pre>         1: enter
           |
	   v
	 2: if (...)
	/        \
       v          v
   3: a = 2     4: a = 3
       |          |
       v          v
   5: b = 3     6: b = 2
         \     /
	  v   v
        7: x = a + b
            |
	    v
	8: print(x)
</pre>
The MOP solution for the final print statement includes the pair (x,5),
since x is assigned the value 5 on both paths to that statement.
However, the greatest solution to the set of equations for this program
(the result computed using the iterative algorithm) finds that
x is not constant at the print statement.
This is because the equations require that n.before be the
meet of m.after for all predecessors m;
in particular, they require that the
"before" set for node 7 (x = a + b) has empty, since
the "after" sets of the two predecessors have (a,2), (b,3),
and (a,3), (b,2), respectively, and the intersection of
those two sets is empty.
Given that value for 7.before, the equations require that
7.after (and 8.before) say that x is not constant.
We can only discover that x is constant after node 7 if both a and b
are constant before node 7.
<p>
In 1977, a paper by Kam and Ullman (Acta Informatica 7, 1977)
extended Kildall's results to show that,
given monotonic dataflow functions:
</p><ul>
  <li> The solutions to the set of equations form a finiteWidthLattice.
  </li><li> The solution computed by the iterative algorithm
       is the <em>greatest</em> solution
       (using the finiteWidthLattice ordering).
  </li><li> If the functions are monotonic but not distributive, then the
       solution computed by the iterative algorithm may
       be less than the MOP solution (using the finiteWidthLattice ordering).
</li></ul>
<p>
To show that the iterative algorithm computes the greatest
solution to the set of equations, we can "transform" the
set of equations into a single, monotonic function L &#8594; L
(for a complete finiteWidthLattice L) as follows:
</p><p>
Consider the right-hand side of each equation to be a "mini-function".
For example, for the two equations:
</p><ul>
  n<sub>3</sub>.before = n<sub>1</sub>.after meet n<sub>2</sub>.after
  <br>n<sub>3</sub>.after = f<sub>3</sub>( n<sub>3</sub>.before )
</ul>
The two mini-functions, g<sub>11</sub> and g<sub>12</sub> are:
<ul>
  g<sub>11</sub>(a, b) = a meet b
  <br>g<sub>12</sub>(a) = f<sub>3</sub>( a )
</ul>
<p>
Define the function that corresponds to all of the equations to be:
</p><ul>
  f( &lt;n<sub>1</sub>.before,n<sub>1</sub>.after,n<sub>2</sub>.before,n<sub>2</sub>.after ...&gt; ) =
  &lt;g<sub>11</sub>(..),g<sub>12</sub>(...),g<sub>21</sub>(..), g<sub>22</sub>(...),...&gt;
</ul>
Where the (...)s are replaced with the appropriate arguments to those
mini-functions.  In other words, function f takes one argument that is
a tuple of values.  It returns a tuple of values, too.  The returned
tuple is computed by applying the mini-functions associated with each
of the dataflow equations to the appropriate inputs (which are part
of the tuple of values that is the argument to function f).
<p>
Note that every <i>fixed point</i> of f is a solution to the set of
equations!
We want the greatest solution. (i.e., the greatest fixed point)
To guarantee that this solution exists we need to know that:
</p><ol>
  <li> the type of f is L&#8594;L, where L is a complete finiteWidthLattice
  </li><li> f is monotonic
</li></ol>
<p>
To show (1), note that the each individual value in the tuple
is an element of a complete finiteWidthLattice. (That is required by Kildall's
framework.)
So since cross product (tupling) preserves completeness,
the tuple itself is an element of a complete finiteWidthLattice.
</p><p>
To show (2), note that the mini-functions that define each
n.after value are monotonic (since those are the dataflow
functions, and we've required that they be monotonic).
It is easy to show that the
mini-functions that define each n.before value are monotonic, too.
</p><p>
For a node n with k predecessors, the equation is:
</p><ul>
  n.before = m<sub><font size="-2">1</font></sub>.after meet m<sub><font size="-2">2</font></sub>.after meet ... meet m<sub><font size="-2">k</font></sub>.after
</ul>
and the corresponding mini-function is:
<ul>
  f(a<sub><font size="-2">1</font></sub>, a<sub><font size="-2">2</font></sub>, ..., a<sub><font size="-2">k</font></sub>) = a<sub><font size="-2">1</font></sub> meet a<sub><font size="-2">2</font></sub> meet ... meet a<sub><font size="-2">k</font></sub>
</ul>
We can prove that these mini-functions are monotonic by induction on k.
<p>
<u>base case k=1</u>
</p><ul>
  f(a<sub><font size="-2">1</font></sub>) = a<sub><font size="-2">1</font></sub>
  <p>
  We must show that given: a &#8838; a', f(a) &#8838; f(a').
  </p><p>
  For this f, f(a) = a, and f(a') = a', so this f is monotonic.
</p></ul>

<p>
<u>base case k=2</u>
</p><ul>
  f(a<sub><font size="-2">1</font></sub>, a<sub><font size="-2">2</font></sub>) = a<sub><font size="-2">1</font></sub> meet a<sub><font size="-2">2</font></sub>
  <p>
  We must show that given: a<sub><font size="-2">1</font></sub> &#8838; a<sub><font size="-2">1</font></sub>' and a<sub><font size="-2">2</font></sub> &#8838; a<sub><font size="-2">2</font></sub>',
f(a<sub><font size="-2">1</font></sub>, a<sub><font size="-2">2</font></sub>) &#8838; f(a<sub><font size="-2">1</font></sub>', a<sub><font size="-2">2</font></sub>').
  </p><ul>
    <li> by the definition of meet we know that:
      <ul> (a<sub><font size="-2">1</font></sub> meet a<sub><font size="-2">2</font></sub>) &#8838; a<sub><font size="-2">1</font></sub> , and
      </ul>
      <ul> (a<sub><font size="-2">1</font></sub> meet a<sub><font size="-2">2</font></sub>) &#8838; a<sub><font size="-2">2</font></sub> 
      </ul>
    </li><li> by the transitivity of &#8838; we know that:
      <ul> (a<sub><font size="-2">1</font></sub> meet a<sub><font size="-2">2</font></sub>) &#8838; a<sub><font size="-2">1</font></sub> &#8838; a<sub><font size="-2">1</font></sub>' implies (a<sub><font size="-2">1</font></sub> meet a<sub><font size="-2">2</font></sub>) &#8838; a<sub><font size="-2">1</font></sub>', and
      </ul>
      <ul>(a<sub><font size="-2">1</font></sub> meet a<sub><font size="-2">2</font></sub>) &#8838; a<sub><font size="-2">2</font></sub> &#8838; a<sub><font size="-2">2</font></sub>' implies (a<sub><font size="-2">1</font></sub> meet a<sub><font size="-2">2</font></sub>) &#8838; a<sub><font size="-2">2</font></sub>'
      </ul>
    </li><li>so (a<sub><font size="-2">1</font></sub> meet a<sub><font size="-2">2</font></sub>) is a lower bound for both a<sub><font size="-2">1</font></sub>' and for a<sub><font size="-2">2</font></sub>'
    </li><li>since (a<sub><font size="-2">1</font></sub>' meet a<sub><font size="-2">2</font></sub>') is (by definition) the <em>greatest</em>
        lower bound of a<sub><font size="-2">1</font></sub>' and a<sub><font size="-2">2</font></sub>', it must be that all other lower bounds
        are less; in particular: (a<sub><font size="-2">1</font></sub> meet a<sub><font size="-2">2</font></sub>) must be &#8838; (a<sub><font size="-2">1</font></sub>' meet a<sub><font size="-2">2</font></sub>').
  </li></ul>
</ul>

<p>
<u>Induction Step</u>
</p><p>
Assume that for all k &lt; n
</p><ul>
  a<sub>1</sub> &#8838; a<sub>1</sub>'
  and a<sub>2</sub> &#8838; a<sub>2</sub>'
  and ... and a<sub>n-1</sub> &#8838; a'<sub>n-1</sub> =&gt;
  <br>f(&lt;a<sub>1</sub>, ..., a<sub>n-1</sub>) &#8838; f(&lt;a<sub>1</sub>',... a'<sub>n-1</sub>&gt;)
</ul>
Now we must show the same thing for k=n
<ul>
  <li> f( &lt;a<sub>1</sub>, a<sub>2</sub>, ..., a<sub>n</sub> &gt;) = a<sub>1</sub> meet a<sub>2</sub> meet ... meet a<sub>n</sub> =
       f( &lt;a<sub>1</sub>, a<sub>2</sub>, ..., a<sub>n-1</sub> &gt;) meet a<sub>n</sub>

  </li><li> let x = f(&lt;a<sub>1</sub>,. .... a<sub>n-1</sub>&gt;)

  </li><li> let x'= f(&lt;a<sub>1</sub>',. .... a<sub>n-1</sub>'&gt;)

  </li><li> the induction hypothesis says: x &#8838; x'
       <br> we need to show: x meet a<sub>n</sub> &#8838; x' meet a<sub>n</sub>'

  </li><li> this is true by the base case k=2!
</li></ul>

<p>
Given that all the mini-functions are monotonic, it is easy to show that
f (the function that works on the tuples that represent the nodes'
before and after sets) is monotonic;
i.e., given two tuples:
</p><ol> t1 =  &lt;e<sub>1</sub>, e<sub>2</sub>, ..., e<sub>n</sub>&gt;, and <br>
     t2 = &lt;e<sub>1</sub>', e<sub>2</sub>', ..., e<sub>n</sub>'&gt;
</ol>
such that: t1 &#8838; t2, we must show f(t1)  &#8838; f(t2).
Recall that, for a cross-product finiteWidthLattice, the ordering is element-wise;
thus, t1 &#8838; t2 means: e<sub>k</sub> &#8838; e<sub>k</sub>', for all k.
We know that all of the mini-functions g are monotonic, so for all k,
g<sub>k</sub>(e<sub>k</sub>) &#8838; g<sub>k</sub>(e<sub>k</sub>').
But since the ordering is element-wise, this is exactly what it means for
f to be monotonic!
<p>
We now know:
</p><ul>
  <li>f is a monotonic function of type L&#8594;L
  </li><li>L is a complete finiteWidthLattice with no infinite descending chains
</li></ul>
<p>
Therefore:
</p><ul>
  <li>f has a greatest fixed point
  </li><li>It can be computed using f(T), f(f(T)), ...
</li></ul>
This is not quite what the iterative algorithm does,
but it is not hard to see that it is equivalent to one that does
just this: initialize
all n.before and n.after to top, then on each iteration,
compute <em>all</em> of the "mini-functions" (i.e., recompute
n.before and n.after for <em>all</em> nodes) simultaneously,
terminating when there is no change.
The actual iterative algorithm presented here is an optimization
in that it only recomputes n.before and n.after for a node n
when the "after" value of some predecessor has changed.


</a><a name="summary">
<h1>SUMMARY</h1>
Given:
   <ul>
     <li>A CFG,
     </li><li>a domain of "dataflow facts" (a complete finiteWidthLattice L),
     </li><li>a monotonic dataflow function for each CFG node, and
     </li><li>an initial dataflow fact (an element of L)
   </li></ul>
the goal of dataflow analysis is to compute a "dataflow fact"
(an element of L) for each CFG node.
Ideally, we want the MOP (meet over all paths) solution, in which
the fact at node n is the combination of the facts induced by all paths to n.
However, for CFGs with cycles, it is not possible to compute this solution
directly.
<p>
Another approach to solving a dataflow problem is to solve a system
of equations that relates the dataflow facts that hold before each
node to the facts that hold after the node.
</p><p>
Kildall showed that if the dataflow functions are distributive,
then the (original version of the)
iterative algorithm always terminates,
and always finds the MOP solution.
Kam and Ullman later showed that if the dataflow functions are
monotonic then the iterative algorithm always finds the
greatest solution to the set of equations.
They also showed that if the functions are monotonic but not
distributive, then that solution is not always the same as
the MOP solution.
It is also true that the
greatest solution to the system of equations is always
an approximation to the MOP solution (i.e.,
may be lower in the finiteWidthLattice of solutions).

</p></a></body></html>